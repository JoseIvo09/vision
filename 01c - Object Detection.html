<!DOCTYPE html>
<html lang="pt-BR">
<head>
  <meta charset="UTF-8">
  <title>Detec√ß√£o de Objetos</title>
  <link rel="stylesheet" href="css/estilos.css">
<style>
  .botoes-finais {
    display: flex;
    flex-direction: column; /* empilha verticalmente */
    align-items: center;     /* centraliza horizontalmente */
    justify-content: center;
    gap: 60px;
    margin-top: 60px;
    margin-bottom: 40px;
  }

  .botao-link {
    font-family: Arial, sans-serif;
    font-size: 44px;
    font-weight: bold;
    text-align: center;
    padding: 10px 40px;
    background-color: #0009E3;
    color: white;
    text-decoration: none;
    border: 3px solid #fff;
    border-radius: 6px;
    cursor: pointer;
    transition: background-color 0.3s;
    transform: scale(1.8); /* Aumenta o tamanho do bot√£o */
    display: flex-block;
  }

  .botao-link:hover {
    background-color: #001233;
  }

    footer {
      background-color: #003366;
      font-size: 32px;
      color: white;
      text-align: center;
      padding: 15px;
      margin-top: 40px;
    }
</style>
</head>
<body>
<h1 id="detec√ß√£o-de-objetos" line="0"> <a href="#detec√ß√£o-de-objetos" class="header_no_underline" line="0"> Detec√ß√£o de Objetos </a> </h1>
<p line="2"> <em line="2"> Detec√ß√£o de objeto </em> √© uma forma de vis√£o computacional na qual um modelo de aprendizado de m√°quina √© treinado para classificar inst√¢ncias individuais de objetos em uma imagem e indicar uma <em line="2"> caixa delimitadora </em> que marca sua localiza√ß√£o. Voc√™ pode pensar nisso como uma progress√£o da <em line="2"> Classifica√ß√£o da imagem </em> (na qual o modelo responde √† pergunta &ldquo;O que √© uma imagem?&rdquo;) Para criar solu√ß√µes onde podemos perguntar ao modelo &ldquo;Quais objetos est√£o nesta imagem e onde est√£o eles?&rdquo;. </p>
<p line="4"> <img src="./images/object-detection.jpg" alt="Um rob√¥ identificando frutas" line="4" /> </p>
<p line="6"> Por exemplo, um supermercado pode usar um modelo de detec√ß√£o de objetos para implementar um sistema de check -out automatizado que digitalize uma correia transportadora usando uma c√¢mera e pode identificar itens espec√≠ficos sem a necessidade de colocar cada item na correia e digitaliz√° -los individualmente. </p>
<p line="8"> O <strong line="8"> Vis√£o Custom </strong> Servi√ßo Cognitivo no Microsoft Azure fornece uma solu√ß√£o baseada em nuvem para criar e publicar modelos de detec√ß√£o de objetos personalizados. </p>
<h2 id="crie-um-recurso-de-vis√£o-personalizado" line="10"> <a href="#crie-um-recurso-de-vis√£o-personalizado" class="header_no_underline" line="10"> Crie um recurso de vis√£o personalizado </a> </h2>
<p line="12"> Para usar o Servi√ßo de Vis√£o Personalizada, voc√™ precisa de um recurso do Azure que possa usar para treinar um modelo e um recurso com o qual voc√™ pode public√° -lo para que os aplicativos usem. Voc√™ pode usar o mesmo recurso para cada uma dessas tarefas ou pode usar recursos diferentes para cada um para alocar custos, desde que os dois recursos sejam criados na mesma regi√£o. O recurso para (ou ambos) tarefas pode ser um recurso geral <strong line="12"> Cognitive Services </strong> ou um recurso espec√≠fico <strong line="12"> de vis√£o personalizada </strong>. Use as seguintes instru√ß√µes para criar um novo recurso <strong line="12"> Vis√£o personalizada </strong> (ou voc√™ pode usar um recurso existente, se tiver um). </p>
<ol line="14"> 
<li line="14"> 
<p line="14"> Em uma nova guia do navegador, abra o portal do Azure no link <a href="https://portal.azure.com" line="14"> https://portal.azure.com </a> e fa√ßa login usando a conta da Microsoft associada √† sua assinatura do Azure. </p>
 </li>
<li line="15"> 
<p line="15"> Selecione o bot√£o <strong line="15"> ÔºãCrie um recurso </strong>, pesquise <em line="15"> Vis√£o personalizada </em> e crie um recurso <strong line="15"> de vis√£o personalizada </strong> com as seguintes configura√ß√µes: </p>
<ul line="16"> 
<li line="16"> <strong line="16"> Criar op√ß√µes </strong>: Ambos </li>
<li line="17"> <strong line="17"> assinatura </strong>: <em line="17"> Sua assinatura do Azure </em> </li>
<li line="18"> <strong line="18"> Grupo de recursos </strong>: <em line="18"> Crie um novo grupo de recursos com um nome exclusivo </em> </li>
<li line="19"> <strong line="19"> Nome </strong>: <em line="19"> Digite um nome √∫nico </em> </li>
<li line="20"> <strong line="20"> Local de treinamento </strong>: <em line="20"> Escolha qualquer regi√£o dispon√≠vel </em> </li>
<li line="21"> <strong line="21"> Pacotes e pre√ßos de treinamento </strong>: F0 </li>
<li line="22"> <strong line="22"> Local de previs√£o </strong>: <em line="22"> O mesmo que o local de treinamento </em> </li>
<li line="23"> <strong line="23"> N√≠vel de pre√ßos de previs√£o </strong>: f0 </li>
 </ul>
<blockquote line="25"> 
<p line="25"> <strong line="25"> Nota </strong>: Se voc√™ j√° possui um servi√ßo de vis√£o personalizado F0 em sua assinatura, selecione <strong line="25"> S0 </strong> para este. </p>
 </blockquote>
 </li>
<li line="27"> 
<p line="27"> Aguarde o recurso a ser criado. </p>
 </li>
 </ol>
<h2 id="crie-um-projeto-de-vis√£o-personalizado" line="29"> <a href="#crie-um-projeto-de-vis√£o-personalizado" class="header_no_underline" line="29"> Crie um projeto de vis√£o personalizado </a> </h2>
<p line="31"> Para treinar um modelo de detec√ß√£o de objetos, voc√™ precisa criar um projeto de vis√£o personalizado com base no seu recurso de treinamento. Para fazer isso, voc√™ usar√° o portal de vis√£o personalizado. </p>
<ol line="33"> 
<li line="33"> Em uma nova guia do navegador, abra o Custom Vision portal no link <a href="https://customvision.ai" line="33"> https://customvision.ai </a>  e fa√ßa login usando a conta da Microsoft associada √† sua assinatura do Azure. </li>
<li line="34"> Crie um novo projeto com as seguintes configura√ß√µes:
<ul line="35"> 
<li line="35"> <strong line="35"> Nome </strong>: Detec√ß√£o de supermercado </li>
<li line="36"> <strong line="36"> Descri√ß√£o </strong>: Detec√ß√£o de objetos para mantimentos. </li>
<li line="37"> <strong line="37"> Recurso </strong>:<em line="37"> O recurso de vis√£o personalizado que voc√™ criou anteriormente </em> </li>
<li line="38"> <strong line="38"> Tipos de projeto </strong>: Detec√ß√£o de objetos </li>
<li line="39"> <strong line="39"> Dom√≠nios </strong>: Geral </li>
 </ul>
 </li>
<li line="40"> Aguarde o projeto ser criado e aberto no navegador. </li>
 </ol>
<h2 id="adicionar-e-marcar-imagens" line="42"> <a href="#adicionar-e-marcar-imagens" class="header_no_underline" line="42"> Adicionar e marcar imagens </a> </h2>
<p line="44"> Para treinar um modelo de detec√ß√£o de objetos, voc√™ precisa fazer upload de imagens que cont√™m as classes que deseja que o modelo identifique e as identifique para indicar caixas delimitadoras para cada inst√¢ncia do objeto. </p>
<ol line="46"> 
<li line="46"> Fa√ßa o download e extraia as imagens de treinamento de <a href="https://aka.ms/fruit-objects" line="46"> https://aka.ms/fruit-objects </a>. A pasta extra√≠da cont√©m uma cole√ß√£o de imagens de frutas. </li>
<li line="47"> No portal de vis√£o personalizado, no seu projeto de detec√ß√£o de objetos, selecione <strong line="47"> Adicione imagens </strong> e fa√ßa o upload de todas as imagens na pasta extra√≠da. </li>
<li line="48"> Depois que as imagens foram enviadas, selecione a primeira a abri -la. </li>
<li line="49"> Segure o mouse sobre qualquer objeto na imagem at√© que uma regi√£o detectada automaticamente seja exibida como a imagem abaixo. Em seguida, selecione o objeto e, se necess√°rio, redimensione a regi√£o para cerc√° -lo. </li>
 </ol>
<p line="51"> <img src="./images/object-region.jpg" alt="A regi√£o padr√£o para um objeto" line="51" /> </p>
<p line="53"> Como alternativa, voc√™ pode simplesmente arrastar o objeto para criar uma regi√£o. </p>
<ol start="5" line="55"> 
<li line="55"> Quando a regi√£o envolver o objeto, adicione uma nova tag com o tipo de objeto apropriado (<em line="55"> Apple </em>,<em line="55"> banana </em>ou<em line="55"> laranja </em>) como mostrado aqui: </li>
 </ol>
<p line="57"> <img src="./images/object-tag.jpg" alt="Um objeto marcado em uma imagem" line="57" /> </p>
<ol start="6" line="59"> 
<li line="59"> Selecione e marque uns aos outros no objeto na imagem, redimensionando as regi√µes e adicionando novas tags conforme necess√°rio. </li>
 </ol>
<p line="61"> <img src="./images/object-tags.jpg" alt="Dois objetos marcados em uma imagem" line="61" /> </p>
<ol start="7" line="63"> 
<li line="63"> 
<p line="63"> Use o link <strong line="63"> &gt; </strong> √† direita para ir para a pr√≥xima imagem e marcar seus objetos. Em seguida, continue trabalhando em toda a cole√ß√£o de imagens, marcando cada ma√ß√£, banana e laranja. </p>
 </li>
<li line="65"> 
<p line="65"> Quando voc√™ terminar de marcar a √∫ltima imagem, feche o <strong line="65"> Image Detail </strong> e na p√°gina <strong line="65"> Training Images </strong>, em <strong line="65"> Tags </strong>, selecione <strong line="65"> Tagged </strong> para ver todas as suas imagens marcadas: </p>
 </li>
 </ol>
<p line="67"> <img src="./images/tagged-images.jpg" alt="Imagens marcadas em um projeto" line="67" /> </p>
<h2 id="treine-e-teste-um-modelo" line="69"> <a href="#treine-e-teste-um-modelo" class="header_no_underline" line="69"> Treine e teste um modelo </a> </h2>
<p line="71"> Agora que voc√™ marcou as imagens em seu projeto, est√° pronto para treinar um modelo. </p>
<ol line="73"> 
<li line="73"> No projeto de vis√£o personalizada, clique em <strong line="73"> Train </strong> para treinar um modelo de detec√ß√£o de objetos usando as imagens marcadas. Selecione a op√ß√£o <strong line="73"> Quick Training </strong>. </li>
<li line="74"> Aguarde a conclus√£o do treinamento (pode levar dez minutos ou mais) e, em seguida, revise as m√©tricas <em line="74"> Precision </em>, <em line="74"> Recall </em> e <em line="74"> mAP </em> de desempenho - elas medem a precis√£o da previs√£o do modelo de classifica√ß√£o e devem ser altas. </li>
<li line="75"> No canto superior direito da p√°gina, clique em <strong line="75"> Quick Test </strong> e, na caixa <strong line="75"> Image URL </strong>, digite <code line="75"> https://aka.ms/Apple-orange </code>
 e visualize a previs√£o gerada. 
Em seguida, feche a janela <strong line="75"> Quick Test </strong>. </li>
 </ol>
<h2 id="publicar-e-consumir-o-modelo-de-detec√ß√£o-de-objetos" line="77"> <a href="#publicar-e-consumir-o-modelo-de-detec√ß√£o-de-objetos" class="header_no_underline" line="77"> Publicar e consumir o modelo de detec√ß√£o de objetos </a> </h2>
<p line="79"> Agora voc√™ est√° pronto para publicar seu modelo treinado e us√° -lo em um aplicativo cliente. </p>
<ol line="81"> 
<li line="81"> No canto superior esquerdo da p√°gina <strong line="81"> de desempenho </strong>, clique em <strong line="81"> üó∏ Publique </strong> para publicar o modelo treinado com as seguintes configura√ß√µes:
<ul line="82"> 
<li line="82"> <strong line="82"> Nome do modelo </strong>: Detect-produce </li>
<li line="83"> <strong line="83"> Recurso de previs√£o </strong>: <em line="83"> Sua vis√£o personalizada </em> <em line="83"> PREFI√á√ÉO </em> <em line="83"> RESCESSO </em>. </li>
 </ul>
 </li>
<li line="84"> Ap√≥s a publica√ß√£o, clique no √≠cone<em line="84"> Configura√ß√µes </em>(‚öô) no canto superior direito da p√°gina <strong line="84"> de desempenho </strong> para visualizar as configura√ß√µes do projeto. Em seguida, em <strong line="84"> general </strong> (√† esquerda), copie o <strong line="84"> ID do projeto </strong> e cole -o na c√©lula de c√≥digo abaixo, substituindo <strong line="84"> your_project_id </strong>. </li>
 </ol>
<blockquote line="86"> 
<p line="86"> (*Se voc√™ usou um recurso <strong line="86"> Cognitive Services </strong> em vez de criar um recurso <strong line="86"> de vis√£o personalizada </strong> no in√≠cio deste exerc√≠cio, voc√™ pode copiar sua chave e endpoint do lado direito das configura√ß√µes do projeto, colar -o na c√©lula de c√≥digo abaixo e execut√° -la para ver os resultados. </p>
 </blockquote>
<ol start="3" line="88"> 
<li line="88"> No canto superior esquerdo da p√°gina de configura√ß√µes <strong line="88"> do projeto </strong>, clique no √≠cone<em line="88"> Projects Projects </em>(üëÅ) para retornar √† p√°gina inicial do portal de vis√£o personalizada, onde seu projeto est√° listado agora. </li>
<li line="89"> Na p√°gina inicial do portal de vis√£o personalizada, no canto superior direito, clique no √≠cone <em line="89"> Configura√ß√µes </em> (‚öô) para visualizar as configura√ß√µes do seu servi√ßo de vis√£o personalizada. Em seguida, em <strong line="89"> Recursos </strong>, expanda seu <em line="89"> prediction </em> resource (<u>not </u> O recurso de treinamento) e copie os valores de <strong line="89"> Key </strong> e <strong line="89"> Endpoint </strong> para a c√©lula de c√≥digo abaixo, substituindo <strong line="89"> YOUR_KEY </strong>  e <strong line="89"> YOUR_ENDPOINT </strong>. </li>
<li line="90"> Execute a c√©lula do c√≥digo abaixo clicando no bot√£o Executar <span>&amp;#9655 </span> (no canto superior esquerdo da c√©lula) para definir as vari√°veis ‚Äã‚Äãpara os valores do seu projeto ID, chave e ponto final. </li>
 </ol>
<pre line="92"> <code class="language-python" line="92"> project_id = 'YOUR_PROJECT_ID' # Replace with your project ID
cv_key = 'YOUR_KEY' # Replace with your prediction resource primary key
cv_endpoint = 'YOUR_ENDPOINT' # Replace with your prediction resource endpoint

model_name = 'detect-produce' # this must match the model name you set when publishing your model iteration exactly (including case)!
print('Ready to predict using model {} in project {}'.format(model_name, project_id))
 </code> </pre>
<p line="101"> Para usar o Servi√ßo de Vis√£o Custom do Python, voc√™ precisar </p>
<pre line="103"> <code class="language-python" line="103"> !pip install azure-cognitiveservices-vision-customvision
 </code> </pre>
<p line="107"> Agora voc√™ pode usar sua chave e endpoint com um cliente de vis√£o personalizado para se conectar ao seu modelo de detec√ß√£o de objeto de vis√£o personalizado. </p>
<p line="109"> Execute a seguinte c√©lula de c√≥digo, que usa seu modelo para detectar itens individuais de produzir em uma imagem. </p>
<blockquote line="111"> 
<p line="111"> <strong line="111"> Nota </strong>: N√£o se preocupe muito com os detalhes do c√≥digo. Ele usa o Python SDK para o servi√ßo de vis√£o personalizada para enviar uma imagem ao seu modelo e recuperar previs√µes para objetos detectados. Cada previs√£o consiste em um nome de classe (<em line="111"> Apple </em>,<em line="111"> banana </em>ou<em line="111"> laranja </em>) e<em line="111"> coordenadas da caixa delimitadora </em>que indicam onde na imagem o objeto previsto foi detectado. O c√≥digo usa essas informa√ß√µes para desenhar uma caixa rotulada em torno de cada objeto na imagem. </p>
 </blockquote>
<pre line="113"> <code class="language-python" line="113"> from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient
from msrest.authentication import ApiKeyCredentials
from matplotlib import pyplot as plt
from PIL import Image, ImageDraw, ImageFont
import numpy as np
import os
%matplotlib inline

# Load a test image and get its dimensions
test_img_file = os.path.join('data', 'object-detection', 'produce.jpg')
test_img = Image.open(test_img_file)
test_img_h, test_img_w, test_img_ch = np.array(test_img).shape

# Get a prediction client for the object detection model
credentials = ApiKeyCredentials(in_headers={&quot;Prediction-key&quot;: cv_key})
predictor = CustomVisionPredictionClient(endpoint=cv_endpoint, credentials=credentials)

print('Detecting objects in {} using model {} in project {}...'.format(test_img_file, model_name, project_id))

# Detect objects in the test image
with open(test_img_file, mode=&quot;rb&quot;) as test_data:
    results = predictor.detect_image(project_id, model_name, test_data)

# Create a figure to display the results
fig = plt.figure(figsize=(8, 8))
plt.axis('off')

# Display the image with boxes around each detected object
draw = ImageDraw.Draw(test_img)
lineWidth = int(np.array(test_img).shape[1]/100)
object_colors = {
    &quot;apple&quot;: &quot;lightgreen&quot;,
    &quot;banana&quot;: &quot;yellow&quot;,
    &quot;orange&quot;: &quot;orange&quot;
}
for prediction in results.predictions:
    color = 'white' # default for 'other' object tags
    if (prediction.probability*100) &gt; 50:
        if prediction.tag_name in object_colors:
            color = object_colors[prediction.tag_name]
        left = prediction.bounding_box.left * test_img_w 
        top = prediction.bounding_box.top * test_img_h 
        height = prediction.bounding_box.height * test_img_h
        width =  prediction.bounding_box.width * test_img_w
        points = ((left,top), (left+width,top), (left+width,top+height), (left,top+height),(left,top))
        draw.line(points, fill=color, width=lineWidth)
        plt.annotate(prediction.tag_name + &quot;: {0:.2f}%&quot;.format(prediction.probability * 100),(left,top), backgroundcolor=color)
plt.imshow(test_img)

 </code> </pre>
<p line="165"> Veja as previs√µes resultantes, que mostram os objetos detectados e a probabilidade de cada previs√£o. </p>
  <!-- Bot√µes final da p√°gina -->
  <div class="botoes-finais">
    <a href="Prova_01c.html" class="botao-link">Exerc√≠cios</a>
  </div>
  <div class="botoes-finais">
    <a href="index.html" class="botao-link">In√≠cio</a>
  </div>
  <footer>
    <p>&copy; 2025 Sinnomar Silva Lino</p>

    <p>Curso Online Tradicional. Todos os direitos reservados.</p>
  </footer>
</body>
</html>
